<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Whisper Transcriber</title>
  
  <!-- Load transformers.min.js as an ES module -->
  <script type="module" src="transformers.min.js"></script>
</head>
<body>
  <h1>Whisper Transcriber</h1>

  <div>
    <label for="audioFile">Upload Audio File:</label>
    <input type="file" id="audioFile" accept="audio/*">
  </div>

  <div>
    <label for="language">Select Language:</label>
    <select id="language">
      <option value="en">English</option>
      <option value="zh">Chinese</option>
    </select>
  </div>

  <button id="transcribeBtn">Transcribe</button>

  <h2>Transcription:</h2>
  <pre id="transcription"></pre>

  <script>
    // Set the path for the WASM files to be the same directory as the HTML file
    const wasmPath = './'; // Same directory as the HTML file

    // Function to load and combine the model files
    async function loadModel() {
      const modelFiles = [];
      
      // Load each of the 7 model chunks
      for (let i = 1; i <= 7; i++) {
        modelFiles.push(fetch(`model/pytorch_model.${i}`).then(response => response.arrayBuffer()));
      }

      // Wait for all model chunks to be loaded
      const modelBuffers = await Promise.all(modelFiles);

      // Combine all the chunks into one ArrayBuffer
      const combinedBuffer = new Uint8Array(modelBuffers.reduce((acc, buffer) => acc.concat(Array.from(new Uint8Array(buffer))), []));
      
      // Configure ONNX Runtime for Web with WASM files (from same directory)
      transformers.WHISPER.setWasmPaths({
        // Path to the WASM files (same directory as index.html)
        ortWasm: `${wasmPath}ort-wasm.wasm`,
        ortWasmSimd: `${wasmPath}ort-wasm-simd.wasm`,
        ortWasmSimdThreaded: `${wasmPath}ort-wasm-simd-threaded.wasm`,
        ortWasmThreaded: `${wasmPath}ort-wasm-threaded.wasm`
      });

      // Load the Whisper model from the combined buffer
      const model = await transformers.WHISPER.loadModel({
        model: new Uint8Array(combinedBuffer),
        config: {
          useThreads: true,
          language: 'en', // Default language
        },
      });

      return model;
    }

    // Transcription logic
    async function transcribe() {
      const audioFile = document.getElementById('audioFile').files[0];
      const language = document.getElementById('language').value;

      if (!audioFile) {
        alert("Please upload an audio file.");
        return;
      }

      // Display loading message
      document.getElementById('transcription').textContent = "Transcribing...";

      // Load the model
      const model = await loadModel();

      // Read the audio file as a blob
      const audioData = await audioFile.arrayBuffer();

      // Transcribe the audio
      try {
        const transcription = await model.transcribe(new Uint8Array(audioData), { language });

        // Display the transcription
        document.getElementById('transcription').textContent = transcription.text;
      } catch (error) {
        document.getElementById('transcription').textContent = "Error during transcription: " + error.message;
      }
    }

    // Add event listener to the button
    document.getElementById('transcribeBtn').addEventListener('click', transcribe);
  </script>
</body>
</html>
